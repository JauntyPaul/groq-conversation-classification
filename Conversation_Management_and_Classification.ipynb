{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3rIS7HELL8vU"
      },
      "outputs": [],
      "source": [
        "# Cell A — install\n",
        "!pip install -q openai jsonschema"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell B — securely set the API key (hidden input)\n",
        "from getpass import getpass\n",
        "import os\n",
        "\n",
        "key = getpass(\"Paste your GROQ API key (input hidden): \")\n",
        "os.environ['GROQ_API_KEY'] = key\n",
        "# base url for Groq's OpenAI-compatible endpoint (default)\n",
        "os.environ['GROQ_BASE_URL'] = 'https://api.groq.com/openai/v1'\n",
        "print(\"API key set in environment. (Hidden from view.)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "haxe8JGXNOYj",
        "outputId": "6eecbb5a-52a1-4b7f-b8c0-483c17d59dc4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Paste your GROQ API key (input hidden): ··········\n",
            "API key set in environment. (Hidden from view.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell C — quick check\n",
        "import os\n",
        "print('GROQ_API_KEY present?:', 'GROQ_API_KEY' in os.environ)\n",
        "print('GROQ_BASE_URL:', os.environ.get('GROQ_BASE_URL'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXFzQRqkNUpk",
        "outputId": "a4f195a4-40bd-4992-a598-80d7d8d49fba"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GROQ_API_KEY present?: True\n",
            "GROQ_BASE_URL: https://api.groq.com/openai/v1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# Task 1: Conversation Manager with Groq API\n",
        "# ========================================\n",
        "\n",
        "# 1. Install dependencies\n",
        "!pip install -q openai jsonschema\n",
        "\n",
        "# 2. Imports and setup\n",
        "import os\n",
        "from typing import List, Dict, Any\n",
        "from dataclasses import dataclass, field\n",
        "from openai import OpenAI\n",
        "\n",
        "\n",
        "# Create Groq client (OpenAI-compatible)\n",
        "client = OpenAI(\n",
        "    api_key=os.getenv(\"GROQ_API_KEY\"),\n",
        "    base_url=\"https://api.groq.com/openai/v1\"\n",
        ")\n",
        "\n",
        "# 3. Groq Chat Completion Helper\n",
        "def groq_chat_completion(messages: List[Dict[str, str]],\n",
        "                         model: str = \"llama-3.1-8b-instant\",\n",
        "                         temperature: float = 0.2) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Calls Groq's OpenAI-compatible endpoint.\n",
        "    Returns dict with assistant message.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        resp = client.chat.completions.create(\n",
        "            model=model,\n",
        "            messages=messages,\n",
        "            temperature=temperature\n",
        "        )\n",
        "        return {\n",
        "            \"choices\": [{\n",
        "                \"message\": {\n",
        "                    \"role\": \"assistant\",\n",
        "                    \"content\": resp.choices[0].message.content\n",
        "                }\n",
        "            }]\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(\"Warning: API call failed ->\", e)\n",
        "        return {\n",
        "            \"choices\": [{\n",
        "                \"message\": {\"role\": \"assistant\", \"content\": \"SIMULATED SUMMARY (API not called).\"}\n",
        "            }]\n",
        "        }\n",
        "\n",
        "# 4. Conversation Manager Class\n",
        "@dataclass\n",
        "class ConversationManager:\n",
        "    history: List[Dict[str, str]] = field(default_factory=list)\n",
        "    summary_history: List[str] = field(default_factory=list)\n",
        "    run_count: int = 0\n",
        "    summarize_every_k: int = 3\n",
        "    summarization_model: str = \"llama-3.1-8b-instant\"\n",
        "\n",
        "    def add_user_message(self, content: str):\n",
        "        self.history.append({\"role\": \"user\", \"content\": content})\n",
        "\n",
        "    def add_assistant_message(self, content: str):\n",
        "        self.history.append({\"role\": \"assistant\", \"content\": content})\n",
        "\n",
        "    def get_last_n_turns(self, n: int) -> List[Dict[str, str]]:\n",
        "        return self.history[-n:]\n",
        "\n",
        "    def truncate_by_chars(self, max_chars: int) -> None:\n",
        "        total = sum(len(m[\"content\"]) for m in self.history)\n",
        "        while total > max_chars and self.history:\n",
        "            removed = self.history.pop(0)\n",
        "            total -= len(removed[\"content\"])\n",
        "\n",
        "    def truncate_by_words(self, max_words: int) -> None:\n",
        "        def total_words(hist):\n",
        "            return sum(len(m[\"content\"].split()) for m in hist)\n",
        "        while total_words(self.history) > max_words and self.history:\n",
        "            self.history.pop(0)\n",
        "\n",
        "    def maybe_summarize(self):\n",
        "        self.run_count += 1\n",
        "        if self.summarize_every_k > 0 and (self.run_count % self.summarize_every_k == 0):\n",
        "            print(f\"Summarizing at run {self.run_count}...\")\n",
        "            summary = self.summarize_history()\n",
        "            self.summary_history.append(summary)\n",
        "            # Replace history with the summary only\n",
        "            self.history = [{\"role\": \"assistant\", \"content\": f\"[SUMMARY]\\n{summary}\"}]\n",
        "            return summary\n",
        "        return None\n",
        "\n",
        "    def summarize_history(self) -> str:\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": \"You are a concise summarizer. Produce a short summary.\"},\n",
        "            {\"role\": \"user\", \"content\": \"Summarize the conversation below.\"}\n",
        "        ]\n",
        "        convo_text = \"\\n\".join([f\"{m['role']}: {m['content']}\" for m in self.history])\n",
        "        messages.append({\"role\": \"user\", \"content\": convo_text})\n",
        "\n",
        "        resp = groq_chat_completion(messages=messages, model=self.summarization_model)\n",
        "        choices = resp.get(\"choices\", [])\n",
        "        if choices:\n",
        "            return choices[0][\"message\"].get(\"content\", \"\")\n",
        "        return \"[EMPTY SUMMARY]\"\n",
        "\n",
        "    def show_history(self):\n",
        "        print(\"--- Conversation History ---\")\n",
        "        for i, m in enumerate(self.history, 1):\n",
        "            print(f\"{i}. {m['role'].upper()}: {m['content']}\")\n",
        "        print(\"---------------------------\")\n",
        "\n",
        "# 5. Demonstration\n",
        "cm = ConversationManager(summarize_every_k=3)\n",
        "\n",
        "# Feed conversation (summary triggers on 3rd run)\n",
        "sample_turns = [\n",
        "    (\"Hi, I need help booking a flight to Bangalore next Friday.\",\n",
        "     \"Sure — what is your preferred airline and departure city?\"),\n",
        "    (\"Preferably early morning. My departure city is Mumbai.\",\n",
        "     \"Got it. Do you have a budget in mind?\"),\n",
        "    (\"Budget under 8k INR. Also, I have a connecting flight constraint.\",\n",
        "     \"I'll look for morning flights under 8k with max one connection.\")\n",
        "]\n",
        "\n",
        "print(\"\\nFeeding sample conversation...\")\n",
        "for user_msg, assistant_msg in sample_turns:\n",
        "    cm.add_user_message(user_msg)\n",
        "    cm.add_assistant_message(assistant_msg)\n",
        "    summary = cm.maybe_summarize()\n",
        "    if summary:\n",
        "        print(\"\\n*** SUMMARY GENERATED ***\\n\", summary)\n",
        "\n",
        "print(\"\\nFinal history after summarization:\")\n",
        "cm.show_history()\n",
        "\n",
        "# Truncation demo\n",
        "print(\"\\nDemonstrating truncation...\")\n",
        "for i in range(6):\n",
        "    cm.add_user_message(f\"User message number {i} with extra text.\")\n",
        "    cm.add_assistant_message(f\"Assistant message number {i} with details.\")\n",
        "\n",
        "print(\"\\nHistory length before truncation:\", len(cm.history))\n",
        "\n",
        "# Last 4 messages\n",
        "last_4 = cm.get_last_n_turns(4)\n",
        "print(\"\\nLast 4 messages:\")\n",
        "for m in last_4:\n",
        "    print(m)\n",
        "\n",
        "# Truncate by chars\n",
        "cm_copy = ConversationManager()\n",
        "cm_copy.history = cm.history.copy()\n",
        "cm_copy.truncate_by_chars(200)\n",
        "print(\"\\nHistory after truncating to 200 chars:\", len(cm_copy.history))\n",
        "\n",
        "# Truncate by words\n",
        "cm_copy2 = ConversationManager()\n",
        "cm_copy2.history = cm.history.copy()\n",
        "cm_copy2.truncate_by_words(50)\n",
        "print(\"\\nHistory after truncating to 50 words:\", len(cm_copy2.history))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pMSh4njObfa",
        "outputId": "fbeadcb3-f225-4a18-d43b-0e5ba5016803"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Feeding sample conversation...\n",
            "Summarizing at run 3...\n",
            "\n",
            "*** SUMMARY GENERATED ***\n",
            " The user needs to book a flight from Mumbai to Bangalore next Friday, with a preferred early morning departure, a budget under 8k INR, and a maximum of one connecting flight.\n",
            "\n",
            "Final history after summarization:\n",
            "--- Conversation History ---\n",
            "1. ASSISTANT: [SUMMARY]\n",
            "The user needs to book a flight from Mumbai to Bangalore next Friday, with a preferred early morning departure, a budget under 8k INR, and a maximum of one connecting flight.\n",
            "---------------------------\n",
            "\n",
            "Demonstrating truncation...\n",
            "\n",
            "History length before truncation: 13\n",
            "\n",
            "Last 4 messages:\n",
            "{'role': 'user', 'content': 'User message number 4 with extra text.'}\n",
            "{'role': 'assistant', 'content': 'Assistant message number 4 with details.'}\n",
            "{'role': 'user', 'content': 'User message number 5 with extra text.'}\n",
            "{'role': 'assistant', 'content': 'Assistant message number 5 with details.'}\n",
            "\n",
            "History after truncating to 200 chars: 5\n",
            "\n",
            "History after truncating to 50 words: 7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O_BESUXczumG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}