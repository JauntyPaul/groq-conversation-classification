{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3rIS7HELL8vU"
      },
      "outputs": [],
      "source": [
        "# Cell A — install\n",
        "!pip install -q openai jsonschema"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell B — securely set the API key (hidden input)\n",
        "from getpass import getpass\n",
        "import os\n",
        "\n",
        "key = getpass(\"Paste your GROQ API key (input hidden): \")\n",
        "os.environ['GROQ_API_KEY'] = key\n",
        "# base url for Groq's OpenAI-compatible endpoint (default)\n",
        "os.environ['GROQ_BASE_URL'] = 'https://api.groq.com/openai/v1'\n",
        "print(\"API key set in environment. (Hidden from view.)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "haxe8JGXNOYj",
        "outputId": "6eecbb5a-52a1-4b7f-b8c0-483c17d59dc4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Paste your GROQ API key (input hidden): ··········\n",
            "API key set in environment. (Hidden from view.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell C — quick check\n",
        "import os\n",
        "print('GROQ_API_KEY present?:', 'GROQ_API_KEY' in os.environ)\n",
        "print('GROQ_BASE_URL:', os.environ.get('GROQ_BASE_URL'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXFzQRqkNUpk",
        "outputId": "a4f195a4-40bd-4992-a598-80d7d8d49fba"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GROQ_API_KEY present?: True\n",
            "GROQ_BASE_URL: https://api.groq.com/openai/v1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# Task 1: Conversation Manager with Groq API\n",
        "# ========================================\n",
        "\n",
        "# 1. Install dependencies\n",
        "!pip install -q openai jsonschema\n",
        "\n",
        "# 2. Imports and setup\n",
        "import os\n",
        "from typing import List, Dict, Any\n",
        "from dataclasses import dataclass, field\n",
        "from openai import OpenAI\n",
        "\n",
        "\n",
        "# Create Groq client (OpenAI-compatible)\n",
        "client = OpenAI(\n",
        "    api_key=os.getenv(\"GROQ_API_KEY\"),\n",
        "    base_url=\"https://api.groq.com/openai/v1\"\n",
        ")\n",
        "\n",
        "# 3. Groq Chat Completion Helper\n",
        "def groq_chat_completion(messages: List[Dict[str, str]],\n",
        "                         model: str = \"llama-3.1-8b-instant\",\n",
        "                         temperature: float = 0.2) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Calls Groq's OpenAI-compatible endpoint.\n",
        "    Returns dict with assistant message.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        resp = client.chat.completions.create(\n",
        "            model=model,\n",
        "            messages=messages,\n",
        "            temperature=temperature\n",
        "        )\n",
        "        return {\n",
        "            \"choices\": [{\n",
        "                \"message\": {\n",
        "                    \"role\": \"assistant\",\n",
        "                    \"content\": resp.choices[0].message.content\n",
        "                }\n",
        "            }]\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(\"Warning: API call failed ->\", e)\n",
        "        return {\n",
        "            \"choices\": [{\n",
        "                \"message\": {\"role\": \"assistant\", \"content\": \"SIMULATED SUMMARY (API not called).\"}\n",
        "            }]\n",
        "        }\n",
        "\n",
        "# 4. Conversation Manager Class\n",
        "@dataclass\n",
        "class ConversationManager:\n",
        "    history: List[Dict[str, str]] = field(default_factory=list)\n",
        "    summary_history: List[str] = field(default_factory=list)\n",
        "    run_count: int = 0\n",
        "    summarize_every_k: int = 3\n",
        "    summarization_model: str = \"llama-3.1-8b-instant\"\n",
        "\n",
        "    def add_user_message(self, content: str):\n",
        "        self.history.append({\"role\": \"user\", \"content\": content})\n",
        "\n",
        "    def add_assistant_message(self, content: str):\n",
        "        self.history.append({\"role\": \"assistant\", \"content\": content})\n",
        "\n",
        "    def get_last_n_turns(self, n: int) -> List[Dict[str, str]]:\n",
        "        return self.history[-n:]\n",
        "\n",
        "    def truncate_by_chars(self, max_chars: int) -> None:\n",
        "        total = sum(len(m[\"content\"]) for m in self.history)\n",
        "        while total > max_chars and self.history:\n",
        "            removed = self.history.pop(0)\n",
        "            total -= len(removed[\"content\"])\n",
        "\n",
        "    def truncate_by_words(self, max_words: int) -> None:\n",
        "        def total_words(hist):\n",
        "            return sum(len(m[\"content\"].split()) for m in hist)\n",
        "        while total_words(self.history) > max_words and self.history:\n",
        "            self.history.pop(0)\n",
        "\n",
        "    def maybe_summarize(self):\n",
        "        self.run_count += 1\n",
        "        if self.summarize_every_k > 0 and (self.run_count % self.summarize_every_k == 0):\n",
        "            print(f\"Summarizing at run {self.run_count}...\")\n",
        "            summary = self.summarize_history()\n",
        "            self.summary_history.append(summary)\n",
        "            # Replace history with the summary only\n",
        "            self.history = [{\"role\": \"assistant\", \"content\": f\"[SUMMARY]\\n{summary}\"}]\n",
        "            return summary\n",
        "        return None\n",
        "\n",
        "    def summarize_history(self) -> str:\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": \"You are a concise summarizer. Produce a short summary.\"},\n",
        "            {\"role\": \"user\", \"content\": \"Summarize the conversation below.\"}\n",
        "        ]\n",
        "        convo_text = \"\\n\".join([f\"{m['role']}: {m['content']}\" for m in self.history])\n",
        "        messages.append({\"role\": \"user\", \"content\": convo_text})\n",
        "\n",
        "        resp = groq_chat_completion(messages=messages, model=self.summarization_model)\n",
        "        choices = resp.get(\"choices\", [])\n",
        "        if choices:\n",
        "            return choices[0][\"message\"].get(\"content\", \"\")\n",
        "        return \"[EMPTY SUMMARY]\"\n",
        "\n",
        "    def show_history(self):\n",
        "        print(\"--- Conversation History ---\")\n",
        "        for i, m in enumerate(self.history, 1):\n",
        "            print(f\"{i}. {m['role'].upper()}: {m['content']}\")\n",
        "        print(\"---------------------------\")\n",
        "\n",
        "# 5. Demonstration\n",
        "cm = ConversationManager(summarize_every_k=3)\n",
        "\n",
        "# Feed conversation (summary triggers on 3rd run)\n",
        "sample_turns = [\n",
        "    (\"Hi, I need help booking a flight to Bangalore next Friday.\",\n",
        "     \"Sure — what is your preferred airline and departure city?\"),\n",
        "    (\"Preferably early morning. My departure city is Mumbai.\",\n",
        "     \"Got it. Do you have a budget in mind?\"),\n",
        "    (\"Budget under 8k INR. Also, I have a connecting flight constraint.\",\n",
        "     \"I'll look for morning flights under 8k with max one connection.\")\n",
        "]\n",
        "\n",
        "print(\"\\nFeeding sample conversation...\")\n",
        "for user_msg, assistant_msg in sample_turns:\n",
        "    cm.add_user_message(user_msg)\n",
        "    cm.add_assistant_message(assistant_msg)\n",
        "    summary = cm.maybe_summarize()\n",
        "    if summary:\n",
        "        print(\"\\n*** SUMMARY GENERATED ***\\n\", summary)\n",
        "\n",
        "print(\"\\nFinal history after summarization:\")\n",
        "cm.show_history()\n",
        "\n",
        "# Truncation demo\n",
        "print(\"\\nDemonstrating truncation...\")\n",
        "for i in range(6):\n",
        "    cm.add_user_message(f\"User message number {i} with extra text.\")\n",
        "    cm.add_assistant_message(f\"Assistant message number {i} with details.\")\n",
        "\n",
        "print(\"\\nHistory length before truncation:\", len(cm.history))\n",
        "\n",
        "# Last 4 messages\n",
        "last_4 = cm.get_last_n_turns(4)\n",
        "print(\"\\nLast 4 messages:\")\n",
        "for m in last_4:\n",
        "    print(m)\n",
        "\n",
        "# Truncate by chars\n",
        "cm_copy = ConversationManager()\n",
        "cm_copy.history = cm.history.copy()\n",
        "cm_copy.truncate_by_chars(200)\n",
        "print(\"\\nHistory after truncating to 200 chars:\", len(cm_copy.history))\n",
        "\n",
        "# Truncate by words\n",
        "cm_copy2 = ConversationManager()\n",
        "cm_copy2.history = cm.history.copy()\n",
        "cm_copy2.truncate_by_words(50)\n",
        "print(\"\\nHistory after truncating to 50 words:\", len(cm_copy2.history))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pMSh4njObfa",
        "outputId": "fbeadcb3-f225-4a18-d43b-0e5ba5016803"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Feeding sample conversation...\n",
            "Summarizing at run 3...\n",
            "\n",
            "*** SUMMARY GENERATED ***\n",
            " The user needs to book a flight from Mumbai to Bangalore next Friday, with a preferred early morning departure, a budget under 8k INR, and a maximum of one connecting flight.\n",
            "\n",
            "Final history after summarization:\n",
            "--- Conversation History ---\n",
            "1. ASSISTANT: [SUMMARY]\n",
            "The user needs to book a flight from Mumbai to Bangalore next Friday, with a preferred early morning departure, a budget under 8k INR, and a maximum of one connecting flight.\n",
            "---------------------------\n",
            "\n",
            "Demonstrating truncation...\n",
            "\n",
            "History length before truncation: 13\n",
            "\n",
            "Last 4 messages:\n",
            "{'role': 'user', 'content': 'User message number 4 with extra text.'}\n",
            "{'role': 'assistant', 'content': 'Assistant message number 4 with details.'}\n",
            "{'role': 'user', 'content': 'User message number 5 with extra text.'}\n",
            "{'role': 'assistant', 'content': 'Assistant message number 5 with details.'}\n",
            "\n",
            "History after truncating to 200 chars: 5\n",
            "\n",
            "History after truncating to 50 words: 7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# Task 2: Conversation Classification with Groq API\n",
        "# ========================================\n",
        "\n",
        "# 1. Define possible intents (fixed set of categories)\n",
        "INTENTS = [\n",
        "    \"book_flight\",\n",
        "    \"cancel_flight\",\n",
        "    \"check_weather\",\n",
        "    \"small_talk\",\n",
        "    \"other\"\n",
        "]\n",
        "\n",
        "# 2. Intent classification helper\n",
        "def classify_intent(user_message: str,\n",
        "                    model: str = \"llama3-8b-8192\") -> str:\n",
        "    \"\"\"\n",
        "    Uses Groq LLM to classify a user message into one of the predefined intents.\n",
        "    Falls back to 'other' if API call fails.\n",
        "    \"\"\"\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": f\"You are an intent classifier. Classify the user message into one of these intents: {INTENTS}. Respond with only the intent name.\"},\n",
        "        {\"role\": \"user\", \"content\": user_message}\n",
        "    ]\n",
        "    try:\n",
        "        resp = client.chat.completions.create(\n",
        "            model=model,\n",
        "            messages=messages,\n",
        "            temperature=0.0  # deterministic classification\n",
        "        )\n",
        "        intent = resp.choices[0].message.content.strip()\n",
        "        if intent not in INTENTS:\n",
        "            intent = \"other\"\n",
        "        return intent\n",
        "    except Exception as e:\n",
        "        print(\"Warning: Classification API failed ->\", e)\n",
        "        return \"other\"\n",
        "\n",
        "# 3. Extend ConversationManager to store intents\n",
        "@dataclass\n",
        "class ClassifiedConversationManager(ConversationManager):\n",
        "    intents: List[str] = field(default_factory=list)\n",
        "\n",
        "    def add_user_message(self, content: str):\n",
        "        # classify intent before storing\n",
        "        intent = classify_intent(content, model=self.summarization_model)\n",
        "        self.history.append({\"role\": \"user\", \"content\": content, \"intent\": intent})\n",
        "        self.intents.append(intent)\n",
        "\n",
        "    def show_history(self):\n",
        "        print(\"--- Classified Conversation History ---\")\n",
        "        for i, m in enumerate(self.history, 1):\n",
        "            role = m['role'].upper()\n",
        "            content = m['content']\n",
        "            intent = m.get('intent', 'N/A')\n",
        "            if role == \"USER\":\n",
        "                print(f\"{i}. {role}: {content}  [Intent: {intent}]\")\n",
        "            else:\n",
        "                print(f\"{i}. {role}: {content}\")\n",
        "        print(\"--------------------------------------\")\n",
        "\n",
        "# 4. Demonstration\n",
        "ccm = ClassifiedConversationManager(summarize_every_k=3)\n",
        "\n",
        "sample_turns = [\n",
        "    (\"Hi, I need help booking a flight to Bangalore next Friday.\",\n",
        "     \"Sure — what is your preferred airline and departure city?\"),\n",
        "    (\"Preferably early morning. My departure city is Mumbai.\",\n",
        "     \"Got it. Do you have a budget in mind?\"),\n",
        "    (\"What's the weather like in Bangalore on that day?\",\n",
        "     \"Let me fetch the forecast for you.\")\n",
        "]\n",
        "\n",
        "print(\"\\nFeeding classified conversation...\")\n",
        "for user_msg, assistant_msg in sample_turns:\n",
        "    ccm.add_user_message(user_msg)\n",
        "    ccm.add_assistant_message(assistant_msg)\n",
        "    summary = ccm.maybe_summarize()\n",
        "    if summary:\n",
        "        print(\"\\n*** SUMMARY GENERATED ***\\n\", summary)\n",
        "\n",
        "print(\"\\nFinal classified history:\")\n",
        "ccm.show_history()\n",
        "\n",
        "print(\"\\nDetected intents:\", ccm.intents)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_BESUXczumG",
        "outputId": "771ec89c-a6c5-4ec1-b8d8-2d8cfff7366a"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Feeding classified conversation...\n",
            "Summarizing at run 3...\n",
            "\n",
            "*** SUMMARY GENERATED ***\n",
            " A user is seeking assistance in booking a flight from Mumbai to Bangalore for next Friday. They prefer an early morning departure and are open to discussing airline and budget options, but the conversation was cut off before further details were discussed.\n",
            "\n",
            "Final classified history:\n",
            "--- Classified Conversation History ---\n",
            "1. ASSISTANT: [SUMMARY]\n",
            "A user is seeking assistance in booking a flight from Mumbai to Bangalore for next Friday. They prefer an early morning departure and are open to discussing airline and budget options, but the conversation was cut off before further details were discussed.\n",
            "--------------------------------------\n",
            "\n",
            "Detected intents: ['book_flight', 'book_flight', 'check_weather']\n"
          ]
        }
      ]
    }
  ]
}